{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10259/2078072913.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(output_file, sep=\",\", encoding=\"utf-8\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChefSam</td>\n",
       "      <td>Sunshine State</td>\n",
       "      <td>Culinarian | Hot Sauce Artisan | Kombucha Brew...</td>\n",
       "      <td>2011-03-23 03:50:13</td>\n",
       "      <td>4680.0</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>6232.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-01 23:59:59</td>\n",
       "      <td>Which #bitcoin books should I think about read...</td>\n",
       "      <td>['bitcoin']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roy‚ö°Ô∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truth-seeking pleb üìö ‚Ä¢ Science üß™ ‚Ä¢ Nature üå±‚òÄÔ∏è ...</td>\n",
       "      <td>2022-01-30 17:41:41</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>9166.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-01 23:59:47</td>\n",
       "      <td>@ThankGodForBTC I appreciate the message, but ...</td>\n",
       "      <td>['Bitcoin']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ethereum Yoda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UP or DOWN...\\n.\\n.\\n.\\n.\\nPrice matters NOT.</td>\n",
       "      <td>2022-07-24 04:50:18</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-01 23:59:42</td>\n",
       "      <td>#Ethereum price update: \\n\\n#ETH $1664.02 USD\\...</td>\n",
       "      <td>['Ethereum', 'ETH', 'Bitcoin', 'BTC', 'altcoin...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viction</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>https://t.co/8M3rgdjwEe\\n\\n#bitcoin #blockchai...</td>\n",
       "      <td>2010-03-26 10:15:26</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-01 23:59:36</td>\n",
       "      <td>CoinDashboard v3.0 is here\\nAvailable on ios a...</td>\n",
       "      <td>['Bitcoin']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rosie</td>\n",
       "      <td>London</td>\n",
       "      <td>The flower language of jasmine is loyalty, res...</td>\n",
       "      <td>2013-02-16 09:57:56</td>\n",
       "      <td>12731.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-01 23:59:32</td>\n",
       "      <td>#Bitcoin Short Term Fractal (4H)üí•\\n\\nIn lower ...</td>\n",
       "      <td>['Bitcoin', 'BTC']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name   user_location  \\\n",
       "0        ChefSam  Sunshine State   \n",
       "1          Roy‚ö°Ô∏è             NaN   \n",
       "2  Ethereum Yoda             NaN   \n",
       "3        Viction   Paris, France   \n",
       "4          Rosie          London   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Culinarian | Hot Sauce Artisan | Kombucha Brew...  2011-03-23 03:50:13   \n",
       "1  Truth-seeking pleb üìö ‚Ä¢ Science üß™ ‚Ä¢ Nature üå±‚òÄÔ∏è ...  2022-01-30 17:41:41   \n",
       "2      UP or DOWN...\\n.\\n.\\n.\\n.\\nPrice matters NOT.  2022-07-24 04:50:18   \n",
       "3  https://t.co/8M3rgdjwEe\\n\\n#bitcoin #blockchai...  2010-03-26 10:15:26   \n",
       "4  The flower language of jasmine is loyalty, res...  2013-02-16 09:57:56   \n",
       "\n",
       "   user_followers  user_friends user_favourites user_verified  \\\n",
       "0          4680.0        2643.0          6232.0         False   \n",
       "1           770.0        1145.0          9166.0         False   \n",
       "2           576.0           1.0             0.0         False   \n",
       "3           236.0        1829.0          2195.0         False   \n",
       "4         12731.0          46.0           134.0         False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2023-03-01 23:59:59  Which #bitcoin books should I think about read...   \n",
       "1  2023-03-01 23:59:47  @ThankGodForBTC I appreciate the message, but ...   \n",
       "2  2023-03-01 23:59:42  #Ethereum price update: \\n\\n#ETH $1664.02 USD\\...   \n",
       "3  2023-03-01 23:59:36  CoinDashboard v3.0 is here\\nAvailable on ios a...   \n",
       "4  2023-03-01 23:59:32  #Bitcoin Short Term Fractal (4H)üí•\\n\\nIn lower ...   \n",
       "\n",
       "                                            hashtags               source  \\\n",
       "0                                        ['bitcoin']   Twitter for iPhone   \n",
       "1                                        ['Bitcoin']   Twitter for iPhone   \n",
       "2  ['Ethereum', 'ETH', 'Bitcoin', 'BTC', 'altcoin...      Twitter Web App   \n",
       "3                                        ['Bitcoin']  Twitter for Android   \n",
       "4                                 ['Bitcoin', 'BTC']      Twitter Web App   \n",
       "\n",
       "  is_retweet  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier et r√©√©crire une version nettoy√©e\n",
    "input_file = \"G-D.csv\"\n",
    "output_file = \"G-D_cleaned.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)  # Entoure tous les champs de guillemets\n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Charger le fichier nettoy√©\n",
    "df = pd.read_csv(output_file, sep=\",\", encoding=\"utf-8\")\n",
    "print(\"Aper√ßu des donn√©es :\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes par colonne :\n",
      "user_name              61\n",
      "user_location       89369\n",
      "user_description    14834\n",
      "user_created         3770\n",
      "user_followers       4577\n",
      "user_friends         4577\n",
      "user_favourites      4577\n",
      "user_verified        4577\n",
      "date                 4577\n",
      "text                 4577\n",
      "hashtags             5384\n",
      "source               5384\n",
      "is_retweet           5443\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier les valeurs manquantes\n",
    "print(\"Nombre de valeurs manquantes par colonne :\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de donn√©es des colonnes :\n",
      "user_name            object\n",
      "user_location        object\n",
      "user_description     object\n",
      "user_created         object\n",
      "user_followers      float64\n",
      "user_friends        float64\n",
      "user_favourites      object\n",
      "user_verified        object\n",
      "date                 object\n",
      "text                 object\n",
      "hashtags             object\n",
      "source               object\n",
      "is_retweet           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les types de donn√©es\n",
    "print(\"Types de donn√©es des colonnes :\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert field to numeric and bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"user_favourites\"] = pd.to_numeric(df[\"user_favourites\"], errors=\"coerce\")\n",
    "\n",
    "# Convertir les colonnes de date\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "df[\"user_created\"] = pd.to_datetime(df[\"user_created\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# Ensure the 'user_verified' column contains only boolean-like values\n",
    "df['user_verified'] = df['user_verified'].apply(lambda x: True if x in [True, 'True', 1] else False if x in [False, 'False', 0] else None)\n",
    "\n",
    "df['user_verified'] = df['user_verified'].astype('boolean')\n",
    "df['is_retweet'] = df['is_retweet'].astype('boolean') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify if the change is happaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de donn√©es apr√®s conversion :\n",
      "user_name                   object\n",
      "user_location               object\n",
      "user_description            object\n",
      "user_created        datetime64[ns]\n",
      "user_followers             float64\n",
      "user_friends               float64\n",
      "user_favourites            float64\n",
      "user_verified              boolean\n",
      "date                datetime64[ns]\n",
      "text                        object\n",
      "hashtags                    object\n",
      "source                      object\n",
      "is_retweet                 boolean\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Types de donn√©es apr√®s conversion :\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop cloum without text and date\n",
    "remplace the othor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_name           0\n",
      "user_location       0\n",
      "user_description    0\n",
      "user_created        0\n",
      "user_followers      0\n",
      "user_friends        0\n",
      "user_favourites     0\n",
      "user_verified       0\n",
      "date                0\n",
      "text                0\n",
      "hashtags            0\n",
      "source              0\n",
      "is_retweet          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10259/3664603681.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"user_verified\"] = df[\"user_verified\"].map({\"True\": True, \"False\": False}).fillna(False)\n",
      "/tmp/ipykernel_10259/3664603681.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"is_retweet\"] = df[\"is_retweet\"].map({\"True\": True, \"False\": False}).fillna(False)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"text\", \"date\"])\n",
    "\n",
    "# Remplacer les valeurs manquantes dans hashtags par \"[]\"\n",
    "df[\"hashtags\"] = df[\"hashtags\"].fillna(\"[]\")\n",
    "\n",
    "# Remplacer les valeurs manquantes dans les colonnes li√©es √† l'utilisateur\n",
    "df[\"user_name\"] = df[\"user_name\"].fillna(\"Unknown\")\n",
    "df[\"user_location\"] = df[\"user_location\"].fillna(\"\")\n",
    "df[\"user_description\"] = df[\"user_description\"].fillna(\"\")\n",
    "df[\"user_followers\"] = df[\"user_followers\"].fillna(0)\n",
    "df[\"user_friends\"] = df[\"user_friends\"].fillna(0)\n",
    "df[\"user_favourites\"] = df[\"user_favourites\"].fillna(0)\n",
    "df[\"user_verified\"] = df[\"user_verified\"].map({\"True\": True, \"False\": False}).fillna(False)\n",
    "df[\"is_retweet\"] = df[\"is_retweet\"].map({\"True\": True, \"False\": False}).fillna(False)\n",
    "df[\"source\"] = df[\"source\"].fillna(\"Unknown\")\n",
    "\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date minimale : 2023-02-25 20:49:09\n",
      "Date maximale : 2023-03-05 23:59:56\n"
     ]
    }
   ],
   "source": [
    "print(\"Date minimale :\", df[\"date\"].min())\n",
    "print(\"Date maximale :\", df[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plage de dates des tweets :\n",
      "Date minimale : 2023-02-25 20:49:09\n",
      "Date maximale : 2023-03-05 23:59:56\n",
      "Nombre total de tweets : 169761\n",
      "\n",
      "Nombre de tweets par heure :\n",
      "hour\n",
      "0     4856\n",
      "1     5208\n",
      "2     4490\n",
      "3     4453\n",
      "4     4311\n",
      "5     4692\n",
      "6     4735\n",
      "7     4959\n",
      "8     6358\n",
      "9     5728\n",
      "10    6446\n",
      "11    7070\n",
      "12    7840\n",
      "13    8265\n",
      "14    8585\n",
      "15    9457\n",
      "16    9811\n",
      "17    9492\n",
      "18    9878\n",
      "19    9331\n",
      "20    9046\n",
      "21    9002\n",
      "22    8185\n",
      "23    7563\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# S'assurer que la colonne date est au format datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# V√©rifier la plage de dates\n",
    "print(\"Plage de dates des tweets :\")\n",
    "print(\"Date minimale :\", df[\"date\"].min())\n",
    "print(\"Date maximale :\", df[\"date\"].max())\n",
    "print(\"Nombre total de tweets :\", len(df))\n",
    "\n",
    "# V√©rifier la distribution des tweets par heure (optionnel, pour voir la r√©partition)\n",
    "df[\"hour\"] = df[\"date\"].dt.hour\n",
    "print(\"\\nNombre de tweets par heure :\")\n",
    "print(df[\"hour\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gener data from banance with the same date as our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es de prix collect√©es :\n",
      "                 date     price\n",
      "0 2023-02-25 00:00:00  23179.84\n",
      "1 2023-02-25 00:01:00  23181.07\n",
      "2 2023-02-25 00:02:00  23172.72\n",
      "3 2023-02-25 00:03:00  23182.30\n",
      "4 2023-02-25 00:04:00  23186.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "from datetime import datetime\n",
    "\n",
    "# Remplace par tes cl√©s API\n",
    "api_key = \"TLXuzjmtV05vOkRYBaeQXWg3p3A6FbsEEVur2ixrJB7bBjY76G0IS1sp4ALhKQjq\"  # Remplace par ta cl√© API\n",
    "api_secret = \"7DNgiq61ajYq7Ul6l8wW5sfUqgSr742PHHqMZgh3Gcn0hnrssvMqKWF80XhKsUtT\"  # Remplace par ta cl√© secr√®te\n",
    "\n",
    "# Initialiser le client Binance\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "# D√©finir la paire de trading et la p√©riode\n",
    "symbol = \"BTCUSDT\"\n",
    "interval = Client.KLINE_INTERVAL_1MINUTE\n",
    "start_time = datetime(2023, 2, 25, 0, 0, 0)  # 5 f√©vrier 2023 00:00:00\n",
    "end_time = datetime(2023, 3, 5, 23, 59, 59)  # 5 mars 2023 23:59:59\n",
    "start_time_ms = int(start_time.timestamp() * 1000)\n",
    "end_time_ms = int(end_time.timestamp() * 1000)\n",
    "\n",
    "# R√©cup√©rer les donn√©es historiques\n",
    "klines = client.get_historical_klines(\n",
    "    symbol=symbol,\n",
    "    interval=interval,\n",
    "    start_str=start_time_ms,\n",
    "    end_str=end_time_ms\n",
    ")\n",
    "\n",
    "# Convertir les donn√©es en DataFrame\n",
    "df_merge_price = pd.DataFrame(klines, columns=[\n",
    "    \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "    \"close_time\", \"quote_asset_volume\", \"num_trades\",\n",
    "    \"taker_buy_base_volume\", \"taker_buy_quote_volume\", \"ignore\"\n",
    "])\n",
    "\n",
    "# Convertir les timestamps en format datetime\n",
    "df_merge_price[\"date\"] = pd.to_datetime(df_merge_price[\"open_time\"], unit=\"ms\")\n",
    "\n",
    "# S√©lectionner les colonnes pertinentes\n",
    "df_merge_price = df_merge_price[[\"date\", \"close\"]]\n",
    "df_merge_price.rename(columns={\"close\": \"price\"}, inplace=True)\n",
    "df_merge_price[\"price\"] = df_merge_price[\"price\"].astype(float)\n",
    "\n",
    "# V√©rifier les donn√©es\n",
    "print(\"Aper√ßu des donn√©es de prix collect√©es :\")\n",
    "print(df_merge_price.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10259/2147767952.py:2: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df[\"date_bucket\"] = df[\"date\"].dt.floor(\"T\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df before merge: Index(['user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'is_retweet', 'date_bucket'],\n",
      "      dtype='object')\n",
      "Columns in df_merge_price: Index(['date', 'price'], dtype='object')\n",
      "Columns after merge and cleanup: Index(['user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'is_retweet', 'date_bucket',\n",
      "       'Bitcoin_Price'],\n",
      "      dtype='object')\n",
      "user_name           0\n",
      "user_location       0\n",
      "user_description    0\n",
      "user_created        0\n",
      "user_followers      0\n",
      "user_friends        0\n",
      "user_favourites     0\n",
      "user_verified       0\n",
      "date                0\n",
      "text                0\n",
      "hashtags            0\n",
      "source              0\n",
      "is_retweet          0\n",
      "date_bucket         0\n",
      "Bitcoin_Price       0\n",
      "dtype: int64\n",
      "169761\n"
     ]
    }
   ],
   "source": [
    "# Arrondir les dates des tweets √† la minute la plus proche\n",
    "df[\"date_bucket\"] = df[\"date\"].dt.floor(\"T\")\n",
    "\n",
    "# Inspect the columns before merging\n",
    "print(\"Columns in df before merge:\", df.columns)\n",
    "print(\"Columns in df_merge_price:\", df_merge_price.columns)\n",
    "\n",
    "# Perform the merge\n",
    "df = df.merge(df_merge_price, left_on=\"date_bucket\", right_on=\"date\", how=\"left\")\n",
    "\n",
    "# Drop unnecessary columns and rename appropriately\n",
    "df = df.drop(columns=[\"date_y\"])  # Drop the duplicate 'date' column from df_merge_price\n",
    "df.rename(columns={\"date_x\": \"date\", \"price\": \"Bitcoin_Price\"}, inplace=True)\n",
    "\n",
    "# Remove duplicate columns if they exist\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Check the columns after cleanup\n",
    "print(\"Columns after merge and cleanup:\", df.columns)\n",
    "\n",
    "# Verify rows with missing Bitcoin_Price\n",
    "print(df.isna().sum())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merger  data of BINANCE with G-D.csv and save finale data into(G-D_final.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier final enregistr√© sous : G-D_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Enregistrer le DataFrame final dans un fichier CSV\n",
    "output_file = \"G-D_final.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Fichier final enregistr√© sous : {output_file}\")\n",
    "# Afficher les premi√®res lignes du DataFrame final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es finales :\n",
      "169761\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"G-D_final.csv\", index=False, encoding=\"utf-8\")\n",
    "# Afficher les premi√®res lignes du DataFrame final          \n",
    "print(\"Aper√ßu des donn√©es finales :\")\n",
    "df.head()\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
